<html>
	<head>
		<style type="text/css">
			body{color: white;
				background-image: url("image/Cover4.jpg");
    				background-repeat: no-repeat;
 				background-attachment: fixed;font-family: sans-serif;}
			p{display: inline-block;}
			img{display: block;}color: white;
			.container{width: 90%;position absolute;margin: auto;}
			.title{position: relative;width: 90%;margin: auto;text-align: center;font-weight: bold;font-size: 18px;padding: 1%;}
			.section{position: relative;width: 90%;margin: auto;padding: 2%;}
			.subsection{position: relative; width: 98%;text-align: justify;padding: 10px;}
			.heading{position: relative; width: 98%;text-align: left;font-size: 14px;font-weight: bold;}
			.text{width: 95%;font-size: 12px;text-align: justify;padding: 10px 0px 10px 0px;}
			.authors{position: relative;width: 80%;margin: auto;padding: 2%;font-style: italic;text-align: center;font-size: 12px;}
			.image{width: 95%;font-size: 12px;text-align: left;}
		</style>
	</head>
	<body>
		<div class="container">
			<div class="title"><font size="+50%" color=" #ff9933">AUDIO QUALITY ENHANCEMENT</font></div>

			<div class="authors">

				<!-- Start edit here  -->
				<font size="+1"><p>Norang Tetarwal, Roll No.: 150102044, Branch: ECE</p>; &nbsp; &nbsp;
				<p>Nishant Bharti,  Roll No.: 150102041, Branch: ECE</p>; &nbsp; &nbsp;
				<p>Ayush Yadav,     Roll No.: 150108005, Branch: EEE</p>; &nbsp; &nbsp;
				<p>Pranav Bhushan,  Roll No.: 150102050, Branch: ECE</p>; &nbsp; &nbsp;</font>
				<!-- Stop edit here -->

			</div>


			<div class="section">
				<div class="heading"><p style="font-size:35px;">Abstract</p></div>
				<div class="text">

					<!-- Start edit here  -->
					<font size="+0.5%">There are several established algorithms specializing in noise reduction of audio and
					speech. We will look at some that are based on the
					Short Time Fourier Transform (STFT). This technique slices the audio in short time frames
					to be able to analyze the local complex frequency spectrum. The noise reduction procedure
					compare the audio spectrum with its estimated noise spectrum to calculate an attenuation
					at each frequency. The attenuated signal is transformed back into time domain. Some of
					the algorithms are based on the Wiener filter or AR-modeling. In old recordings a certain
					level of noise may be wanted to preserve authenticity. Thus a noise floor generator may be
					implemented.</font>
					<!-- Stop edit here -->

				</div>
			</div>

			<div class="section">
				<div class="heading"><p style="font-size:35px;">1. Introduction</p></div>
				<div class="text">

					<!-- Start edit here  -->
					<font size="+0.1%">We will look at noise reduction by digital signal processing. The goal is to denoise
					old audio recordings, hence we utilised at established speech enhancement- and
					audio restoration algorithms. To realize the restoration tool we use the numerical computation
					environment, MATLAB.</font>
					<!-- Stop edit here -->

				</div>

				<div class="subsection">
					<div class="heading"><p style="font-size:20px;">1.1 Introduction to Problem</p></div>
					<div class="text">

						<!-- Start edit here  -->
						<font size="+0.1%">This project aims at enhancing the quality of noisy audio signals by denoising them. 
						</font><!-- Stop edit here -->

					</div>
				</div>

				<div class="subsection">
					<div class="heading"><p style="font-size:20px;">1.2 Figure</p></div>
					<div class="image">

						<!-- Start edit here  -->
						
						<img src="image/Audio.jpg" alt="This text displays when the image is lppp" />
						
						<!-- Stop edit here -->

					</div>
					<div></div>
				</div>
				<div class="subsection">
					<div class="heading"><p style="font-size:20px;">1.3 Literature Review</p></div>
					<div class="text">

						<!-- Start edit here  -->
						<font size="+0.1%">
						<p>The first algorithms for noise reduction within a signal, were developed in the late 70’s and early 80’s to digitally enhance
						speech perception. They are based around the Short-Time Fourier Transform (STFT). This
						technique analyzes the audio by extracting short time frames and transforming them into
						the frequency domain. Throughout the 90's, many papers have been released focusing on
						audio restoration. There are primarily two popular papers presenting two strikingly different algorithms.
						</p>
						<p>The First is a Wiener filter based on the approach articulated in Godsill and Rayner's book, 'Digital Audio Restoration - A Statistical Model'. The Second is a more complex algorithm
						presented in the article 'Elimination of the Musical Noise Phenomenon with the Ephraim
						and Malah Suppressor' by Oliver Cappé. There exist other algorithms not based on
						STFT, but they are not discussed in as detail. We tried to analyze the same thing using Wavelet
						Transform, by implementing the Haar wavelet, doing the Soft & Hard Thresholding across the median value obtained and reconstructing the output denoised signal using inverse wavelet transform.</p>
						</font><!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading"><p style="font-size:20px;">1.4 Proposed Approach</p></div>
					<div class="text">

						<!-- Start edit here  -->
						<font size="+0.1%">
						Extract	noiseprint from loaded Wav File then compute its STFT and estimate Noise spectrum. 
						Meanwhile compute STFT of Original signal and use a Suppression rule on estimated Noise spectrum.
						Then after compute Inverse STFT after suppressing noise.
						Pass this through Low pass filter.
						Since some of the original piece is lost in residue add required Noise Floor.
						</font><!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					
				</div>
			</div>

			<div class="section">
				<div class="heading"><p style="font-size:35px;">2. Applied Approach</p></div>
				<div class="image">

						<!-- Start edit here  -->
						
						<img src="image/Main1.JPG" alt="This text displays when the image is umavailable"/>
						
						<!-- Stop edit here -->

					</div>
				<div class="text">

					<!-- Start edit here  -->
					<font size="+0.1%">
						Audio Quality Enhancement of Speech Signal
					</font><!-- Stop edit here -->

				</div>
				
				<div class="subsection">
					<div class="heading"><p style="font-size:20px;">2.1 Short-Time fourier transform</p></div>
					<div class="text">

						<!-- Start edit here  -->
						<font size="+0.1%"> 
							<p>The STFT is a signal processing technique used to determine the phase and frequency of
non-stationary time signals. Small sections or short time frames are choped up,
analyzing each frame as a stationary part using the Fourier transform. The discrete STFT of the signal x(n) is:
							<div style="display: flex; justify-content: center;">
								<img src="Theory/STFT1.PNG" alt="STFT" align="middle">
								</div>
</p>
						<p>We invert the STFT using an Overlap-Add (OLA) method. First each frame has to be
inverse transformed. <div style="display: flex; justify-content: center;">
								<img src="Theory/STFT2.PNG" alt="STFT" align="middle">
								</div></p>
					
					<p> x(n) is now recognized as the chopped up overlapping sections abbreviated xp(l).
gcorr(l) is a gain correction function to reverse the amplitude modifications done by the
overlap and windowing. 
					<div style="display: flex; justify-content: center;">
								<img src="Theory/STFT3.PNG" alt="STFT" align="middle">
								</div>
					</p>
				<p>With less than 50% overlap the inverse window is used. This is only applicable for the
Hamming window or other non zero tapered windows. With 50% or more overlap the
signal has been amplified (almost uniformly depending on window type) by the window
integral, or discrete sum, divided by the step size. The inverse is used to scale down the
signal. This is also valid for zero tapered windows.To regain the complete signal the overlapping sections are added together.
<div style="display: flex; justify-content: center;">
								<img src="Theory/STFT4.PNG" alt="STFT" align="middle">
				</div> </p>
			
			
						</font><!-- Stop edit here -->

					</div>
				</div>
				
				<div class="subsection">
					<div class="heading"><p style="font-size:20px;">2.2 Wiener-filter
</p></div>
					<div class="text">

						<!-- Start edit here  -->
						<font size="+0.1%"> <p> The Wiener filter suppress additive noise by comparing the noisy signal with an estimated
noiseless signal. The filter is derived from the performance criterion of Minimum Mean
Square Error (MMSE), and takes the following form in the frequency domain:
							<div style="display: flex; justify-content: center;">
								<img src="Theory/Wienerfilter.PNG" alt="STFT" align="middle">
								</div>
							</p>
						<p>where ω is the continuous frequency [4]. SX(ω) is the energy density spectrum of the
noiseless signal, and SD(ω) is the energy density spectrum of the noise.
						<div style="display: flex; justify-content: center;">
								<img src="Theory/Wienerfilter2.PNG" alt="STFT" align="middle">
								</div></p>
						</font><!-- Stop edit here -->

					</div>
				</div>
				
				<div class="subsection">
					<div class="heading"><p style="font-size:20px;">2.3 Stationary Noise Reduction</p></div>
					<div class="text">

						<!-- Start edit here  -->
						<font size="+0.1%"> <p> There are three basic suppression rules. The principle is transformed into the discrete domain by substituting the continuous
frequency variable, ω with the discrete frequency variable, k. This gives a pseudo-Wiener filter solution.
							<div style="display: flex; justify-content: center;">
								<img src="Theory/NoiseSup1.PNG" alt="STFT" align="middle">
							</div></p>
							<p><div style="display: flex; justify-content: center;">
								<img src="Theory/NoiseSup2.PNG" alt="STFT" align="middle">
							</div></p>
							<p><div style="display: flex; justify-content: center;">
								<img src="Theory/NoiseSup3.PNG" alt="STFT" align="middle">
							</div></p>
						
							

						</font><!-- Stop edit here -->

					</div>
				</div>

			<div class="subsection">
					<div class="heading"><p style="font-size:20px;">2.4 The Ephraim-Malah Suppression Rule
</p></div>
					<div class="text">

						<!-- Start edit here  -->
						<font size="+0.1%"> <p> The basic suppression rules can result in some annoying artifacts called musical noise. This
occurs when the estimated noise spectrum mismatch the noisy data, leaving peaks at random
frequencies. To suppress this we need a smoothing effect in our suppression rule. The smoothing
effect is implemented by analyzing both the current and previous restored frame, combining
them in a feedback topology. The EMSR is derived with a performance criterion of
MMSE, based on modeling speech and noise as independent random Gaussian variables.
The restored phase is shown to be the same as in the noisy audio. We skip the derivation
and head straight for the good stuff.
The EMSR as defined by Cappé :
							<div style="display: flex; justify-content: center;">
								<img src="Theory/ESMR1.PNG" alt="STFT" align="middle">
							</div></p>
						<p> Rpost is the a posteriori SNR at each frequency bin. In other words the SNR of the latest
frame. Rprio is the a priori SNR, weighted between the previous and latest frame. M(θ)
stems from a confluent hypergeometric function.
							<div style="display: flex; justify-content: center;">
								<img src="Theory/ESMR2.PNG" alt="STFT" align="middle">
							</div></p>
							
					<p> p denotes the frame number. The definition by Cappé introduce a new parameter, α
(0 ≤ α ≤ 1). The parameter acts as a weighting factor, controlling the amount of feedback.
As α approaches 1 the SNR of the previous restored frame dominates. P(x) ensures zero or
positive output. The EMSR is derived with the assumption that the signal is always present. The suppression
rule can be further expanded to include the probability of signal absence, q(k). This
includes a new definition of Rprio.

						<div style="display: flex; justify-content: center;">
								<img src="Theory/ESMR3.PNG" alt="STFT" align="middle">
							</div></p>

<p> where the new R(0)prio replace all the previous instances of Rprio. A likelihood ratio, Λ is
defined to modify the original EMSR.
	<div style="display: flex; justify-content: center;">
								<img src="Theory/ESMR4.PNG" alt="STFT" align="middle">
							</div></p>

<p>where µ is defined as:
	<div style="display: flex; justify-content: center;">
								<img src="Theory/ESMR5.PNG" alt="STFT" align="middle">
							</div></p>

<p> Finally, the modified EMSR is:
	<div style="display: flex; justify-content: center;">
								<img src="Theory/ESMR6.PNG" alt="STFT" align="middle">
							</div></p>
<p> We've used a Buterworth Filter at the end to fine-tune our output even further and get an even purer Denoised Output.


	


						</font><!-- Stop edit here -->

					</div>
				</div>
				</div>
				

					</div>

				


				
				<div class="subsection">
					<div class="heading"><p style="font-size:20px;">2.5 Noise Spectrum Estimation</p></div>
					<div class="text">

						<!-- Start edit here  -->
						<font size="+0.1%"> <p> The noise print may vary over a longer period than one frame. To get a good estimate
the noise print is partitioned with the same window function, frame- and step size as the
noise reduction process. To estimate the spectrum from the DFT components the Fourier
transform is done as well. The spectrums are then averaged. When the STFT with overlap
is used to compute an averaged power spectrum, it is often called Welch’s method.
Typical averaging methods are the arithmetic mean, Root Mean Square (RMS) and maxima.
							<div style="display: flex; justify-content: center;">
								<img src="Theory/Noise1.PNG" alt="STFT" align="middle">
							</div></p>
						<p><div style="display: flex; justify-content: center;">
								<img src="Theory/Noise2.PNG" alt="STFT" align="middle">
							</div></p>
						</p>
						
						</font><!-- Stop edit here -->

					</div>
				</div>
				
				
			</div>
					<div class="subsection">
					<div class="heading"><p style="font-size:20px;">2.6 Use of Window Function</p></div>
					<div class="text">

						<!-- Start edit here  -->
						<font size="+0.1%"> <p> 
							<div style="display: flex; justify-content: center;">
								<img src="Theory/window_function.PNG" alt="STFT" align="middle">
							</div></p>
						
						</font><!-- Stop edit here -->

					</div>
				</div>
				
				
			</div>
					
				
				
			</div>
</div>
</div>
</div>
</div>
</div>

			<div class="section">
				<div class="heading"><p style="font-size:35px;">3. Experiments &amp; Results</p></div>
				<div class="subsection">
					<div class="heading"><p style="font-size:20px;">3.1 Dataset Description</p></div>
					<div class="text">

						<!-- Start edit here  -->
						<font size="+0.1%">A test was performed using a synthetic example, where a clean audio source
						is contaminated by a random noise generating process. Then the output signal
						obtained after denoising was close to original peice. 
						</font><!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading"><p style="font-size:20px;">3.2 Discussion</p></div>
					<div class="text">

						<!-- Start edit here  -->
						<font size="+0.1%">Much of original signal data was lost initially.
						But later we deviced a way to recover components from noise residue by adding noise floor gain.
						</font><!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading"><p style="font-size:20px;">3.3 Audio Samples & their Denoised Outputs</p></div>
					<div class="text">

						<!-- Start edit here  -->
						<font size="+0.1%"> 
							
							<table>
 								 <tr>
									 <td><p>First Sample</p></td>
 									   <td><audio controls align="left">
 						 <source src="Sample input-outputs/Sample_input3.wav" type="audio/wav">
						</audio></td>
   									<td><audio controls align="right">
 						 <source src="Sample input-outputs/Sample_output3.wav" type="audio/wav">
						</audio></td>
   
								  </tr>
								<tr>
									<td><p> Second Sample</p></td>
 									   <td>	<audio controls align="left">
 						 <source src="Sample input-outputs/Sample_input1.wav" type="audio/wav">
						</audio>
							</td>
   									<td><audio controls align="right">
 						 <source src="Sample input-outputs/Sample_output1.wav" type="audio/wav">
						</audio></td>
   
								  </tr>
								<tr>
									<td><p>  Third Sample</p></td>
 									   <td><audio controls align="left">
 						 <source src="Sample input-outputs/Sample_input2.wav" type="audio/wav">
						</audio></td>
   									<td><audio controls align="right">
 						 <source src="Sample input-outputs/Sample_output2.wav" type="audio/wav">
						</audio></td>
   
								  </tr>
							</table>
							
						
						
						
						
							
						
							
							
						
							
							
						</font><!-- Stop edit here -->

					</div>
				</div>
			</div>
			</div>
			
			
	

			<div class="section">
				<div class="heading"><p style="font-size:35px;">4.Run Codes</p></div>
				<div class="image">

						<!-- Start edit here  --><font size="+0.1%">
					<p align="left"></p>
					<iframe src="html/spectrum_estimator.html" width="550" marginwidth="50" height="300" scrolling="yes" align="left">
  
</iframe>
							<!-- Start edit here  --><font size="+0.1%">
					  <p align="right" ></p>
					<iframe src="html/noise_suppressor.html" marginwidth="50" width="550" height="300" scrolling="yes" align="right">
<p>&nbsp; <br/> </p>

</iframe>
							<!-- Start edit here  --><font size="+0.1%">
					<p align="left"></p>
					<iframe src="html/Ephram_malah.html" marginwidth="50" width="550" height="300" scrolling="yes" align="left">
  
</iframe>
							<!-- Start edit here  --><font size="+0.1%">
					  <p align="right"></p>
					<iframe src="html/LOWPASS_FILTER.html" marginwidth="50" width="550" height="300" scrolling="yes" align="right">

</iframe>
							<!-- Start edit here  --><font size="+0.1%">
					<p align="middle"><font size ="6">Complete Assembled Code</font></p>
					<iframe src="html/Final_Project.html" width="1140" height="500" scrolling="yes" align="middle" >
  
</iframe>
					

				
						</font>
						<!-- Stop edit here -->

					</div>
				<div class="text">

					<!-- Start edit here  -->
					<font size="+0.1%">
						
					</font><!-- Stop edit here -->

				</div>
			</div>
			
			<div class="section">
				<div class="heading"><p style="font-size:35px;">5. Conclusions</p></div>
				<div class="subsection">
					<div class="heading"><p style="font-size:20px;">5.1 Summary</p></div>
					<div class="text">

						<!-- Start edit here  --><font size="+0.1%">
						<p>A Speech Quality Enhancement tool was created with MATLAB which was greatly efficient. We were
able to reduce noise in old noisy audio recordings by a significant amount. Some
basic and state of the art noise reduction algorithms were successfully realized. The EMSR
algorithm gave the most advanced results, although the basic spectral
subtraction methods also gave a satisfactory result but with less complexity. 
We built a solid framework around the STFT.</p> 

<p>The program is easily expandable to support
more algorithms. Noise reduction by STFT approach proved to be a
massive research field with all its algorithms and parameters. We can use various types of Noises along with White 
Gaussian Noise because the method applied compares the Noise Spectral Density with the noisy signal.</p>

<p>We learnt the applications of various DSP techniques like FFT, STFT, Weiner filter, Butterworth Filter 
studied in our course.</p> 
</font>
						</font><!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading"><p style="font-size:20px;">5.2 Future Extensions</p></div>
					<div class="text">

						<!-- Start edit here  --><font size="+0.1%">
						<p>Here, We have done the analysis using only White Gaussian Noise. Many other tests can be performed using other types of examples, where a clean audio source
is contaminated by a random noise generating process. Also more window functions could be tested.</p>
 
<p>In theory, higher resolution would give more precise spectrum estimations, that could help differentiate noise and good audio.
Some other suppression rules have been proposed. Ephraim and Malah proposed a logspectral EMSR. There are also other suppression rules proposed
by Wolfe and Godsill. A modification to improve the EMSR’s transient distortion is also proposed and called the W2 modification.</p> 

<p>Another good implementation would be a noise gate in between the noise suppressor
and noise floor generator. The noise gate could probably do some of the noise removal that
the low pass filter now does, but without making the signal less attractive as it appears that the output obtained is somewhat like suppressed. 
On the other hand a noise gate could be preferred in a restoration environment.</p>

						more algorithms.</font>
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

		</div>
	
	<div class="section">
				<div class="heading"><p style="font-size:35px;">6.References</p></div>
				<div class="image">

						<!-- Start edit here  --><font size="+0.1%">
						<ul>
 							 <li>Wikipedia. Noise gate, May 2013. http://en.wikipedia.org/wiki/Noise_
gate.</li>
 							 <li>Wikipedia. Short-time fourier transform, May 2013. http://en.wikipedia.org/
wiki/Short-time_Fourier_transform.</li>
 							 <li>Wikipedia. Window function, May 2013. http://en.wikipedia.org/wiki/
Window_function.</li>
							<li>Wikipedia. Digital filter, May 2013. http://en.wikipedia.org/wiki/Digital_
filter.</li>
							<li>John G. Proakis and Dimitris G. Manolakis. Digital Signal Processing third edition.
Prentice-Hall International, Inc., 1995.
</li>
							<li>Wikipedia. Wiener filter, March 2013. http://en.wikipedia.org/wiki/
Wiener_filter</li>
							<li>Y. Ephraim and D. Malah. Speech enhancement using optimal non-linear spectral
amplitude estimation. IEEE Transactions on Acoustics, Speech and Signal Processing, 1983.</li>
							<li> S. Canazza, G. De Poli, G. A. Mian, and A. Scarpa. Real time comparison of audio
restoration methods based on short time spectral attenuation. Proceedings of the COST
G-6 Conference on Digital Audio Effects (DAFX-01), Limerick, Ireland, December 2001.</li>
							<li>Christoph Domes. Hiss reduction, basic methods for audio restoration. Digitale Audiotechnik
2, Signal Processing and Speech Communication Laboratory, Graz University of
Technology, May 2009.
</li>
							<li>Y. Ephraim and D. Malah. Speech enhancement using a minimum mean-square error
log-spectral amplitude estimator. IEEE Transactions on Acoustics, Speech and Signal
Processing, vol. ASSP-33, NO. 2, April 1985.</li>
							<li> A. Akbari Azirani, R. Le Bouquin Jeannés, and G. Faucon. Speech enhancement using
a wiener filtering under signal presence uncertainty. Laboratoire du Traitement du Signal
et de l’Image - Université de Rennes,</li>
							<li>Joseph Nuzman. Audio restoration: An investigation of digital methods for click removal
and hiss reduction. University of Maryland Institute for Advanced Computer Studies,
January 2004.</li>
							
						
						</ul> 
						
						</font>
						<!-- Stop edit here -->

					</div>
				<div class="text">

					<!-- Start edit here  -->
					<font size="+0.1%">
						
					</font><!-- Stop edit here -->

				</div>
			</div>
	
	</body>
</html>
